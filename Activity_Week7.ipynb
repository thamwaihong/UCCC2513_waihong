{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d378525",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e256f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# Python 3.7 is required\n",
    "assert sys.version_info >= (3,7)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304878d",
   "metadata": {},
   "source": [
    "## Activity 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285b6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('pineapple.jfif', 0)\n",
    "\n",
    "eq1 = cv.equalizeHist(img)\n",
    "eq2 = cv.equalizeHist(eq1)\n",
    "\n",
    "cv.imshow('Original | Equalized 1 | Equalized 2', np.hstack((img, eq1, eq2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# No difference between the first equalized image and second equalized image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dbaab",
   "metadata": {},
   "source": [
    "## Activity 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31d965",
   "metadata": {},
   "source": [
    "### (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79b8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif')\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, th = cv.threshold(img_gray, 60, 255, cv.THRESH_BINARY)\n",
    "\n",
    "def thresh_callback(val):\n",
    "    krnl_size = (1, 3, 5, 7, 9, 11)\n",
    "    \n",
    "    sobely8u = cv.Sobel(th, cv.CV_8U, 0, 1, ksize = krnl_size[val])\n",
    "    \n",
    "    cv.imshow('Sobel_y', sobely8u)\n",
    "    \n",
    "cv.namedWindow('window')\n",
    "cv.imshow('window', img_gray)\n",
    "cv.createTrackbar('Sobel:', 'window', 0, 5, thresh_callback)\n",
    "thresh_callback(1)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "#Kernel Size = 3 is the most appropriate value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea0952",
   "metadata": {},
   "source": [
    "### (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e6c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Gaussian Blur\n",
    "img = cv.imread('electronic.jfif', 0)\n",
    "\n",
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "sobelx = cv.Sobel(img_blur, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobely = cv.Sobel(img_blur, cv.CV_64F, 0, 1, ksize = 3)\n",
    "\n",
    "abs_sobelx_u8 = cv.convertScaleAbs(sobelx)\n",
    "abs_sobely_u8 = cv.convertScaleAbs(sobely)\n",
    "\n",
    "mag_edge = cv.addWeighted(abs_sobelx_u8, 0.5, abs_sobely_u8, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9368335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Gaussian Blur\n",
    "sobelx1 = cv.Sobel(img, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobely1 = cv.Sobel(img, cv.CV_64F, 0, 1, ksize = 3)\n",
    "\n",
    "abs_sobelx_u8_1 = cv.convertScaleAbs(sobelx1)\n",
    "abs_sobely_u8_1 = cv.convertScaleAbs(sobely1)\n",
    "\n",
    "mag_edge_1 = cv.addWeighted(abs_sobelx_u8_1, 0.5, abs_sobely_u8_1, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020fc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Gaussian Blur\n",
    "cv.imshow('With Gaussian', np.hstack((img, mag_edge)))\n",
    "\n",
    "#Without Gaussian Blur\n",
    "cv.imshow('Without Gaussian', np.hstack((img, mag_edge_1)))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb15ad",
   "metadata": {},
   "source": [
    "### (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5896dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Blur\n",
    "img = cv.imread('electronic.jfif', 0)\n",
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "laplacian = cv.Laplacian(img, cv.CV_64F, ksize = 3)\n",
    "laplacian_8u = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "cv.imshow('Laplacian', laplacian_8u)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e623242",
   "metadata": {},
   "source": [
    "## Activity 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1da3f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sobel\n",
    "img = cv.imread('pineapple.jfif', 0)\n",
    "\n",
    "sobelx1 = cv.Sobel(img, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobely1 = cv.Sobel(img, cv.CV_64F, 0, 1, ksize = 3)\n",
    "\n",
    "abs_sobelx_u8_1 = cv.convertScaleAbs(sobelx1)\n",
    "abs_sobely_u8_1 = cv.convertScaleAbs(sobely1)\n",
    "\n",
    "mag_edge = cv.addWeighted(abs_sobelx_u8_1, 0.5, abs_sobely_u8_1, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e204e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplacian\n",
    "laplacian = cv.Laplacian(img, cv.CV_64F, ksize = 3)\n",
    "laplacian_8u = np.uint8(np.absolute(laplacian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d133578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prewitt\n",
    "kernel_x = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernel_y = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "\n",
    "prewitt_x = cv.filter2D(img, -1, kernel_x)\n",
    "prewitt_y = cv.filter2D(img, -1, kernel_y)\n",
    "\n",
    "prewitt = prewitt_x + prewitt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bd1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scharr derivatives\n",
    "scharr_x = cv.Scharr(img, cv.CV_64F, 1, 0)\n",
    "scharr_y = cv.Scharr(img, cv.CV_64F, 0, 1)\n",
    "\n",
    "abs_scharrx = np.uint8(np.absolute(scharr_y))\n",
    "abs_scharry = np.uint8(np.absolute(scharr_y))\n",
    "\n",
    "scharr = cv.bitwise_or(abs_scharrx, abs_scharry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12a6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canny\n",
    "canny = cv.Canny(img, 100, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2f094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result\n",
    "original = cv.imread('pineapple.jfif')\n",
    "\n",
    "cv.imshow('Original', original)\n",
    "cv.imshow('Sobel', np.hstack((img, mag_edge)))\n",
    "cv.imshow('Laplacian', laplacian_8u)\n",
    "cv.imshow('Prewitt', prewitt)\n",
    "cv.imshow('Scharr', scharr)\n",
    "cv.imshow('Canny', canny)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6ca69",
   "metadata": {},
   "source": [
    "1. Sobel makes the picture looks like more natural like hand sketch.\n",
    "2. While Laplacian and Scharr make the picture not clear and much of noise.\n",
    "3. Prewitt is more clear than Sobel where we can see the shape clearly.\n",
    "4. Canny has separate the object with the background obviously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e7890",
   "metadata": {},
   "source": [
    "## Activity 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c259ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif')\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "can = cv.Canny(img_gray, 193, 600)\n",
    "\n",
    "ret, thresh = cv.threshold(img_gray, 100, 255, cv.THRESH_BINARY_INV)\n",
    "contours, hierachy = cv.findContours(can, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "x, y, w, h = cv.boundingRect(contours[2])\n",
    "cv.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "cv.imshow('Laptop', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a74b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
